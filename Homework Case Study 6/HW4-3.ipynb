{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for Research Homework: Week 4, Case Study 3\n",
    "\n",
    "Homophily is a property of networks.  Homophily occurs when nodes that are neighbors in a network also share a characteristic more often than nodes that are not network neighbors.  In this case study, we will investigate homophily of several characteristics of individuals connected in social networks in rural India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "In Exercise 1, we will calculate the chance homophily for an arbitrary characteristic. Homophily is the proportion of edges in the network whose constituent nodes share that characteristic.\n",
    "\n",
    "How much homophily do we expect by chance? If characteristics are distributed completely randomly, the probability that two nodes \\(x\\) and \\(y\\) share characteristic \\(a\\) is the probability both nodes have characteristic \\(a\\) , which is the marginal probability of \\(a\\) squared. The total probability that nodes \\(x\\) and \\(y\\) share their characteristic is therefore the sum of the square of the marginal probabilities of each characteristic in the network.\n",
    "\n",
    "<strong>Instructions</strong>\n",
    "<ul><li>Create a function <code>marginal_prob</code> that takes a dictionary <code>chars</code> with personal IDs as keys and characteristics as values; it should return a dictionary with characteristics as keys and their marginal probability (frequency of occurence of a characteristic divided by the sum of frequencies of each characteristic) as values.</li>\n",
    "<li>Create a function <code>chance_homophily(chars)</code> that takes a dictionary <code>chars</code> defined as above and computes the chance homophily (homophily due to chance alone) for that characteristic.</li>\n",
    "<li>A sample of three peoples' favorite colors is given in <code>favorite_colors</code>. Use your function to compute the chance homophily in this group, and store it as <code>color_homophily</code>.</li>\n",
    "<li>Print <code>color_homophily</code>.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def frequency(chars):\n",
    "    frequencies     = dict(Counter(chars.values()))\n",
    "    sum_frequencies = sum(frequencies.values())\n",
    "    for key in frequencies:\n",
    "        frequencies[key] /= sum_frequencies\n",
    "    return frequencies\n",
    "        \n",
    "        \n",
    "def chance_homophily(chars):\n",
    "    frequencies = frequency(chars)\n",
    "    return np.sum(np.square(list(frequencies.values())))\n",
    "\n",
    "favorite_colors = {\n",
    "    \"ankit\":  \"red\",\n",
    "    \"xiaoyu\": \"blue\",\n",
    "    \"mary\":   \"blue\"\n",
    "}\n",
    "\n",
    "color_homophily = chance_homophily(favorite_colors)\n",
    "print(color_homophily)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "In the remaining exercises, we will calculate actual homophily in these village and compare the obtained values to those obtained by chance. In this exercise, we subset the data into individual villages and store them.\n",
    "\n",
    "#### Instructions \n",
    "\n",
    "- `individual_characteristics.dta` contains several characteristics for each individual in the dataset such as age, religion, and caste. Use the `pandas` library to read in and store these characteristics as a dataframe called `df`.\n",
    "- Store separate datasets for individuals belonging to Villages 1 and 2 as `df1` and `df2`, respectively.\n",
    "- Note that some attributes may be missing for some individuals. In this case study, we will ignore rows of data where some column information is missing.\n",
    "- Use the head method to display the first few entries of `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (20,27,41,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>village</th>\n",
       "      <th>adjmatrix_key</th>\n",
       "      <th>pid</th>\n",
       "      <th>hhid</th>\n",
       "      <th>resp_id</th>\n",
       "      <th>resp_gend</th>\n",
       "      <th>resp_status</th>\n",
       "      <th>age</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>privategovt</th>\n",
       "      <th>work_outside</th>\n",
       "      <th>work_outside_freq</th>\n",
       "      <th>shgparticipate</th>\n",
       "      <th>shg_no</th>\n",
       "      <th>savings</th>\n",
       "      <th>savings_no</th>\n",
       "      <th>electioncard</th>\n",
       "      <th>rationcard</th>\n",
       "      <th>rationcard_colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100201</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>38</td>\n",
       "      <td>HINDUISM</td>\n",
       "      <td>...</td>\n",
       "      <td>PRIVATE BUSINESS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>100202</td>\n",
       "      <td>1002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Spouse of Head of Household</td>\n",
       "      <td>27</td>\n",
       "      <td>HINDUISM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>100601</td>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>29</td>\n",
       "      <td>HINDUISM</td>\n",
       "      <td>...</td>\n",
       "      <td>OTHER LAND</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>100602</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Spouse of Head of Household</td>\n",
       "      <td>24</td>\n",
       "      <td>HINDUISM</td>\n",
       "      <td>...</td>\n",
       "      <td>PRIVATE BUSINESS</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>100701</td>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>58</td>\n",
       "      <td>HINDUISM</td>\n",
       "      <td>...</td>\n",
       "      <td>OTHER LAND</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  village  adjmatrix_key     pid  hhid  resp_id  resp_gend  \\\n",
       "0           0        1              5  100201  1002        1          1   \n",
       "1           1        1              6  100202  1002        2          2   \n",
       "2           2        1             23  100601  1006        1          1   \n",
       "3           3        1             24  100602  1006        2          2   \n",
       "4           4        1             27  100701  1007        1          1   \n",
       "\n",
       "                   resp_status  age  religion  ...       privategovt  \\\n",
       "0            Head of Household   38  HINDUISM  ...  PRIVATE BUSINESS   \n",
       "1  Spouse of Head of Household   27  HINDUISM  ...               NaN   \n",
       "2            Head of Household   29  HINDUISM  ...        OTHER LAND   \n",
       "3  Spouse of Head of Household   24  HINDUISM  ...  PRIVATE BUSINESS   \n",
       "4            Head of Household   58  HINDUISM  ...        OTHER LAND   \n",
       "\n",
       "  work_outside work_outside_freq shgparticipate shg_no savings savings_no  \\\n",
       "0          Yes               0.0             No    NaN      No        NaN   \n",
       "1          NaN               NaN             No    NaN      No        NaN   \n",
       "2           No               NaN             No    NaN      No        NaN   \n",
       "3           No               NaN            Yes    1.0     Yes        1.0   \n",
       "4           No               NaN             No    NaN      No        NaN   \n",
       "\n",
       "  electioncard rationcard rationcard_colour  \n",
       "0          Yes        Yes             GREEN  \n",
       "1          Yes        Yes             GREEN  \n",
       "2          Yes        Yes             GREEN  \n",
       "3          Yes         No               NaN  \n",
       "4          Yes        Yes             GREEN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.read_csv(\"individual_characteristics.csv\")\n",
    "df1 = df[df[\"village\"]==1]\n",
    "df2 = df[df[\"village\"]==2]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "\n",
    "In this exercise, we define a few dictionaries that enable us to look up the sex, caste, and religion of members of each village by personal ID. For Villages 1 and 2, their personal IDs are stored as `pid`.\n",
    "\n",
    "#### Instructions \n",
    "- Define dictionaries with personal IDs as keys and a given covariate for that individual as values. Complete this for the sex, caste, and religion covariates, for Villages 1 and 2.\n",
    "- For Village 1, store these dictionaries into variables named `sex1`, `caste1`, and `religion1`.\n",
    "- For Village 2, store these dictionaries into variables named `sex2`, `caste2`, and `religion2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{200101: 'GENERAL',\n",
       " 200201: 'GENERAL',\n",
       " 200202: 'GENERAL',\n",
       " 200401: 'GENERAL',\n",
       " 200402: 'GENERAL',\n",
       " 200601: 'GENERAL',\n",
       " 200602: 'GENERAL',\n",
       " 200603: 'GENERAL',\n",
       " 200604: 'GENERAL',\n",
       " 200901: 'GENERAL',\n",
       " 200902: 'OBC',\n",
       " 201001: 'GENERAL',\n",
       " 201002: 'GENERAL',\n",
       " 201102: 'GENERAL',\n",
       " 201103: 'GENERAL',\n",
       " 201201: 'GENERAL',\n",
       " 201202: 'GENERAL',\n",
       " 201203: 'GENERAL',\n",
       " 201204: 'GENERAL',\n",
       " 201205: 'GENERAL',\n",
       " 201206: 'GENERAL',\n",
       " 201301: 'GENERAL',\n",
       " 201302: 'GENERAL',\n",
       " 201501: 'OBC',\n",
       " 201502: 'OBC',\n",
       " 201601: 'GENERAL',\n",
       " 201602: 'GENERAL',\n",
       " 201801: 'GENERAL',\n",
       " 201802: 'GENERAL',\n",
       " 202001: 'GENERAL',\n",
       " 202002: 'GENERAL',\n",
       " 202401: 'GENERAL',\n",
       " 202402: 'GENERAL',\n",
       " 202501: 'GENERAL',\n",
       " 202502: 'GENERAL',\n",
       " 202601: 'GENERAL',\n",
       " 202602: 'GENERAL',\n",
       " 202801: 'GENERAL',\n",
       " 202802: 'OBC',\n",
       " 202803: 'OBC',\n",
       " 203201: 'GENERAL',\n",
       " 203202: 'GENERAL',\n",
       " 203301: 'GENERAL',\n",
       " 203302: 'GENERAL',\n",
       " 203601: 'OBC',\n",
       " 203602: 'OBC',\n",
       " 203701: 'GENERAL',\n",
       " 203702: 'GENERAL',\n",
       " 204501: 'SCHEDULED CASTE',\n",
       " 204502: 'SCHEDULED CASTE',\n",
       " 204504: 'SCHEDULED CASTE',\n",
       " 204601: 'SCHEDULED CASTE',\n",
       " 204602: 'SCHEDULED CASTE',\n",
       " 205001: 'SCHEDULED CASTE',\n",
       " 205002: 'SCHEDULED CASTE',\n",
       " 205004: 'SCHEDULED CASTE',\n",
       " 205101: 'SCHEDULED CASTE',\n",
       " 205102: 'SCHEDULED CASTE',\n",
       " 205301: 'SCHEDULED CASTE',\n",
       " 205302: 'SCHEDULED CASTE',\n",
       " 205401: 'SCHEDULED CASTE',\n",
       " 205402: 'SCHEDULED CASTE',\n",
       " 205501: 'SCHEDULED CASTE',\n",
       " 205502: 'SCHEDULED CASTE',\n",
       " 205601: 'SCHEDULED CASTE',\n",
       " 205602: 'SCHEDULED CASTE',\n",
       " 206001: 'SCHEDULED CASTE',\n",
       " 206002: 'SCHEDULED CASTE',\n",
       " 206201: 'SCHEDULED CASTE',\n",
       " 206202: 'SCHEDULED CASTE',\n",
       " 206601: 'SCHEDULED CASTE',\n",
       " 206602: 'SCHEDULED CASTE',\n",
       " 206901: 'SCHEDULED CASTE',\n",
       " 206902: 'SCHEDULED CASTE',\n",
       " 206903: 'SCHEDULED CASTE',\n",
       " 206904: 'SCHEDULED CASTE',\n",
       " 206908: 'SCHEDULED CASTE',\n",
       " 206909: 'SCHEDULED CASTE',\n",
       " 207101: 'SCHEDULED CASTE',\n",
       " 207102: 'SCHEDULED CASTE',\n",
       " 207401: 'SCHEDULED CASTE',\n",
       " 207402: 'SCHEDULED CASTE',\n",
       " 207403: 'SCHEDULED CASTE',\n",
       " 207801: 'SCHEDULED CASTE',\n",
       " 207802: 'SCHEDULED CASTE',\n",
       " 208102: 'SCHEDULED CASTE',\n",
       " 208201: 'SCHEDULED CASTE',\n",
       " 208202: 'SCHEDULED CASTE',\n",
       " 208301: 'SCHEDULED CASTE',\n",
       " 208302: 'SCHEDULED CASTE',\n",
       " 208401: 'SCHEDULED CASTE',\n",
       " 208402: 'SCHEDULED CASTE',\n",
       " 208501: 'SCHEDULED CASTE',\n",
       " 208502: 'SCHEDULED CASTE',\n",
       " 208503: 'SCHEDULED CASTE',\n",
       " 208601: 'SCHEDULED CASTE',\n",
       " 208602: 'SCHEDULED CASTE',\n",
       " 208603: 'SCHEDULED CASTE',\n",
       " 208701: 'SCHEDULED CASTE',\n",
       " 208801: 'SCHEDULED CASTE',\n",
       " 208802: 'SCHEDULED CASTE',\n",
       " 208803: 'SCHEDULED CASTE',\n",
       " 208804: 'SCHEDULED CASTE',\n",
       " 208805: 'SCHEDULED CASTE',\n",
       " 208901: 'SCHEDULED CASTE',\n",
       " 208902: 'SCHEDULED CASTE',\n",
       " 209301: 'SCHEDULED CASTE',\n",
       " 209302: 'SCHEDULED CASTE',\n",
       " 209501: 'SCHEDULED CASTE',\n",
       " 209502: 'SCHEDULED CASTE',\n",
       " 209503: 'SCHEDULED CASTE',\n",
       " 209504: 'SCHEDULED CASTE',\n",
       " 209601: 'SCHEDULED CASTE',\n",
       " 209602: 'SCHEDULED CASTE',\n",
       " 209801: 'SCHEDULED CASTE',\n",
       " 209802: 'SCHEDULED CASTE',\n",
       " 209803: 'SCHEDULED CASTE',\n",
       " 209804: 'SCHEDULED CASTE',\n",
       " 209805: 'OBC',\n",
       " 210401: 'OBC',\n",
       " 210402: 'OBC',\n",
       " 210403: 'OBC',\n",
       " 210404: 'OBC',\n",
       " 210501: 'OBC',\n",
       " 210502: 'OBC',\n",
       " 210505: 'OBC',\n",
       " 210601: 'GENERAL',\n",
       " 210602: 'GENERAL',\n",
       " 210701: 'GENERAL',\n",
       " 210702: 'GENERAL',\n",
       " 210901: 'OBC',\n",
       " 210902: 'GENERAL',\n",
       " 211101: 'GENERAL',\n",
       " 211102: 'GENERAL',\n",
       " 211801: 'GENERAL',\n",
       " 211802: 'OBC',\n",
       " 211805: 'GENERAL',\n",
       " 211901: 'GENERAL',\n",
       " 211902: 'GENERAL',\n",
       " 211903: 'GENERAL',\n",
       " 211904: 'GENERAL',\n",
       " 212101: 'GENERAL',\n",
       " 212102: 'GENERAL',\n",
       " 212301: 'GENERAL',\n",
       " 212302: 'GENERAL',\n",
       " 212303: 'GENERAL',\n",
       " 212304: 'GENERAL',\n",
       " 212306: 'GENERAL',\n",
       " 212307: 'GENERAL',\n",
       " 212401: 'GENERAL',\n",
       " 212402: 'GENERAL',\n",
       " 213001: 'GENERAL',\n",
       " 213002: 'GENERAL',\n",
       " 213003: 'GENERAL',\n",
       " 213004: 'GENERAL',\n",
       " 213101: 'GENERAL',\n",
       " 213102: 'GENERAL',\n",
       " 213701: 'GENERAL',\n",
       " 213702: 'GENERAL',\n",
       " 213801: 'GENERAL',\n",
       " 213802: 'OBC',\n",
       " 214101: 'GENERAL',\n",
       " 214102: 'GENERAL',\n",
       " 214103: 'GENERAL',\n",
       " 214104: 'GENERAL',\n",
       " 214201: 'GENERAL',\n",
       " 214202: 'GENERAL',\n",
       " 214203: 'GENERAL',\n",
       " 214206: 'GENERAL',\n",
       " 214401: 'GENERAL',\n",
       " 214402: 'GENERAL',\n",
       " 214501: 'GENERAL',\n",
       " 214502: 'GENERAL',\n",
       " 214503: 'GENERAL',\n",
       " 214504: 'GENERAL',\n",
       " 214901: 'GENERAL',\n",
       " 214902: 'GENERAL',\n",
       " 215401: 'GENERAL',\n",
       " 215402: 'GENERAL',\n",
       " 215701: 'GENERAL',\n",
       " 215702: 'GENERAL',\n",
       " 215703: 'GENERAL',\n",
       " 215704: 'GENERAL',\n",
       " 215901: 'GENERAL',\n",
       " 215902: 'GENERAL',\n",
       " 216101: 'GENERAL',\n",
       " 216102: 'OBC',\n",
       " 216401: 'OBC',\n",
       " 216402: 'GENERAL',\n",
       " 216403: 'GENERAL',\n",
       " 216404: 'GENERAL',\n",
       " 216701: 'GENERAL',\n",
       " 216702: 'GENERAL',\n",
       " 216801: 'GENERAL',\n",
       " 216802: 'GENERAL',\n",
       " 216803: 'OBC',\n",
       " 216804: 'OBC',\n",
       " 216901: 'GENERAL',\n",
       " 216902: 'GENERAL',\n",
       " 216903: 'GENERAL',\n",
       " 216904: 'OBC',\n",
       " 216905: 'GENERAL',\n",
       " 216906: 'GENERAL'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex1      = df1.set_index(\"pid\")[\"resp_gend\"].to_dict()\n",
    "caste1    = df1.set_index(\"pid\")[\"caste\"].to_dict()\n",
    "religion1 = df1.set_index(\"pid\")[\"religion\"].to_dict()\n",
    "\n",
    "sex2      = df2.set_index(\"pid\")[\"resp_gend\"].to_dict()\n",
    "caste2    = df2.set_index(\"pid\")[\"caste\"].to_dict()\n",
    "religion2 = df2.set_index(\"pid\")[\"religion\"].to_dict()\n",
    "\n",
    "#religion2\n",
    "#religion1\n",
    "caste2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise, we will print the chance homophily of several characteristics of Villages 1 and 2. \n",
    "\n",
    "#### Instructions \n",
    "-  Use `chance_homophily` to compute the chance homophily for sex, caste, and religion In Villages 1 and 2. Is the chance homophily for any attribute very high for either village?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Village 1 chance of same sex: 0.5027299861680701\n",
      "Village 1 chance of same caste: 0.6741488509791551\n",
      "Village 1 chance of same religion: 0.9804896988521925\n",
      "Village 2 chance of same sex: 0.5005945303210464\n",
      "Village 2 chance of same caste: 0.425368244800893\n",
      "Village 2 chance of same religion: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here.\n",
    "print(\"Village 1 chance of same sex:\", chance_homophily(sex1))\n",
    "print(\"Village 1 chance of same caste:\", chance_homophily(caste1))\n",
    "print(\"Village 1 chance of same religion:\", chance_homophily(religion1))\n",
    "\n",
    "print(\"Village 2 chance of same sex:\", chance_homophily(sex2))\n",
    "print(\"Village 2 chance of same caste:\", chance_homophily(caste2))\n",
    "print(\"Village 2 chance of same religion:\", chance_homophily(religion2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "In this exercise, we will create a function that computes the observed homophily given a village and characteristic.\n",
    "\n",
    "#### Instructions \n",
    "- Complete the function `homophily()`, which takes a network `G`, a dictionary of node characteristics `chars`, and node IDs `IDs`. For each node pair, determine whether a tie exists between them, as well as whether they share a characteristic. The total count of these is `num_ties` and `num_same_ties`, respectively, and their ratio is the homophily of chars in `G`. Complete the function by choosing where to increment `num_same_ties` and `num_ties`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homophily(G, chars, IDs):\n",
    "    \"\"\"\n",
    "    Given a network G, a dict of characteristics chars for node IDs,\n",
    "    and dict of node IDs for each node in the network,\n",
    "    find the homophily of the network.\n",
    "    \"\"\"\n",
    "    num_same_ties = 0\n",
    "    num_ties = 0\n",
    "    for n1, n2 in G.edges():\n",
    "        if IDs[n1] in chars and IDs[n2] in chars:\n",
    "            if G.has_edge(n1, n2):\n",
    "                num_ties += 1\n",
    "                if chars[IDs[n1]] == chars[IDs[n2]]:\n",
    "                    num_same_ties += 1\n",
    "    return (num_same_ties / num_ties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "In this exercise, we will obtain the personal IDs for Villages 1 and 2. These will be used in the next exercise to calculate homophily for these villages.\n",
    "\n",
    "#### Instructions \n",
    "- In this dataset, each individual has a personal ID, or PID, stored in `key_vilno_1.csv` and `key_vilno_2.csv` for villages 1 and 2, respectively. `data_filepath1` and `data_filepath2` contain the URLs to the datasets used in this exercise. Use `pd.read_csv` to read in and store `key_vilno_1.csv` and `key_vilno_2.csv` as `pid1` and `pid2` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File key_vilno_1.csvkey_vilno_1.csv does not exist: 'key_vilno_1.csvkey_vilno_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-27fe8f95c911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Enter code here!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpid1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_filepath1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"key_vilno_1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpid2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_filepath2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"key_vilno_2.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File key_vilno_1.csvkey_vilno_1.csv does not exist: 'key_vilno_1.csvkey_vilno_1.csv'"
     ]
    }
   ],
   "source": [
    "data_filepath1 = \"key_vilno_1.csv\"\n",
    "data_filepath2 = \"key_vilno_2.csv\"\n",
    "\n",
    "# Enter code here!\n",
    "pid1 = pd.read_csv(data_filepath1 + \"key_vilno_1.csv\", dtype=int, header = None)\n",
    "pid2 = pd.read_csv(data_filepath2 + \"key_vilno_2.csv\", dtype=int, header = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "In this exercise, we will compute the homophily of several network characteristics for Villages 1 and 2 and compare them to homophily due to chance alone. The networks for these villages have been stored as networkx graph objects `G1` and `G2`.\n",
    "\n",
    "#### Instructions \n",
    "\n",
    "- Use your `homophily()` function to compute the observed homophily for sex, caste, and religion in Villages 1 and 2. Print all six values.\n",
    "- Use the `chance_homophily()` to compare these values to chance homophily. Are these values higher or lower than that expected by chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "A1 = np.array(pd.read_csv(\"https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@adj_allVillageRelationships_vilno1.csv\", index_col=0))\n",
    "A2 = np.array(pd.read_csv(\"https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@adj_allVillageRelationships_vilno2.csv\", index_col=0))\n",
    "G1 = nx.to_networkx_graph(A1)\n",
    "G2 = nx.to_networkx_graph(A2)\n",
    "\n",
    "pid1 = pd.read_csv(data_filepath1, dtype=int)['0'].to_dict()\n",
    "pid2 = pd.read_csv(data_filepath2, dtype=int)['0'].to_dict()\n",
    "\n",
    "# Enter your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
